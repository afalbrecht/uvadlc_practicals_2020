#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=lstm_job
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=00:45:00
#SBATCH --mem=32000M
#SBATCH --output=slurm_output_%A.out

module purge
module load 2019
module load Python/3.7.5-foss-2019b
module load CUDA/10.1.243
module load cuDNN/7.6.5.32-CUDA-10.1.243
module load NCCL/2.5.6-CUDA-10.1.243
module load Anaconda3/2018.12

# Your job starts in the directory where you call sbatch
cd "$HOME/uvadlc_practicals_2020/assignment_2/2_recurrentnns_gnns/code/Part 1"
# Activate your environment
source activate dl2020
# Run your code
srun python -u train.py --model_type='LSTM' --device='cuda:0' --mode='eval' --train_steps=1000

# seq_length = [4,5,6]
# optimizer = Adam
# learning_rate = 0.0001
# update_iterations = 3000
# batch_size = 256
# nr_hidden = 256
# max_norm = 10
# initialization = Kaiming_normal